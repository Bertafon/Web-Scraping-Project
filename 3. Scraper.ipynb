{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0556a39e-524e-48bf-8aee-c628c1b5c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7148515-223e-476c-a13a-47ad0c217616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### część 1 lista wszystkich produktów\n",
    "\n",
    "# strona uniemożliwia pobranie linków do produktów na zakładce przy pomocy BS lub Scrapy. Konieczne jest użycie Selenium.\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "d = webdriver.Chrome(executable_path='chromedriver') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60c5033-760c-4349-aed5-f64292b96fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.get(\"https://www.notino.pl/perfumy/\") # link do kategorii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03153578-8d9d-4d0f-b23b-986ce76f1503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maksymalny zakres kart na stronie\n",
    "max_zakres = int(d.find_elements(\"xpath\",\"//span[@data-testid='page-item']\")[-1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98741794-0ab5-4d94-8827-26ae4e9af0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [] # lista linkow do kazdego produktu\n",
    "url = 'https://www.notino.pl/perfumy/?f=0-1-55544'\n",
    "for i in range(1,max_zakres+1): \n",
    "    url = url.replace(f'?f={i-1}',f'?f={i}') # kolejne zakładki powstają według takiego schematu\n",
    "    d.get(url) \n",
    "    produkty = d.find_elements(\"xpath\",\"//div[@data-testid='product-container']//a\") # odnajduj linki do produktów\n",
    "    sleep(2)\n",
    "    for i in produkty:\n",
    "        products.append(i.get_attribute('href')) # dopisuj linki do listy\n",
    "products = list(set(products)) # unikatowe wartości\n",
    "niechciane_adresy = ['https://www.notino.pl/opakowanie-prezentowe/', 'https://www.notino.pl/mobile-application/'] # zbędne adresy\n",
    "for adres in niechciane_adresy:\n",
    "    if adres in products:\n",
    "        products.remove(adres) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af98857-7257-4729-87a9-4d1f22921aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e7fd9d-5156-4077-b7bc-a8e1f8c26e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapisuje liste ze wszystkimi linkami do pliku csv, żeby nie było potrzeby za każdym razem powtarzać powyższego\n",
    "df = pd.DataFrame(products)\n",
    "df.dropna(inplace=True)\n",
    "df.to_csv(\"link_list.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19e04c2-5c62-41a5-ba45-56c93f6a4dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### część 2 scrapowanie poszczegolnych produktów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d9d70a-2eaf-4ddd-98c2-7d11d5fa645f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import json\n",
    "import logging\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.linkextractors import LinkExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "707ddfd1-8998-43dc-8ffe-70c35a804297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# format pliku wynikowego\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('output.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21bb0381-a4ef-429d-b934-fdcf176196ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductsSpider(scrapy.Spider):\n",
    "    \n",
    "    name = 'products'\n",
    "    start_urls = products\n",
    "            \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, \n",
    "        'FEED_FORMAT':'json',                                 \n",
    "        'FEED_URI': 'output.json'\n",
    "       ,'DOWNLOAD_DELAY': 3 # opóźnienie w sekundach\n",
    "       , 'RANDOMIZE_DOWNLOAD_DELAY' : True # losowość opóźnień: (0.5,1.5)*lag\n",
    "    }\n",
    "    \n",
    "    def parse_product(self,response):\n",
    "        \n",
    "        xpath_name = '//title/text()' # ścieżka do nazwy \n",
    "        xpath_EAN = '//script[@type=\"application/ld+json\"]//text()' # ścieżka do EAN\n",
    "        xpath_promo = '//div[@id = \"pd-price\"]/span/@content' # ścieżka do ceny promocyjnej\n",
    "        xpath_regural = '//span[@data-testid = \"originalPriceLineThroughWrapper\"]/span/span/@content' # ścieżka do ceny regularnej\n",
    "            \n",
    "        name = response.xpath(xpath_name).get()[:-12]\n",
    "        EAN = json.loads(response.xpath(xpath_EAN).get())['gtin13']\n",
    "        price = response.xpath(xpath_promo).get()\n",
    "        regural = response.xpath(xpath_regural).get()\n",
    "        \n",
    "        yield {\n",
    "                'Name': name,\n",
    "                'EAN': EAN,\n",
    "                'cena': regural,\n",
    "                'cena promo': price,\n",
    "                'url': response.url\n",
    "                }\n",
    "    \n",
    "    def parse(self,response):\n",
    "        \n",
    "        # ponownie dany produkt może mieć wiele objętości\n",
    "        xpath_objetosc = '//div[@id = \"pdVariantsTile\"]//@href' \n",
    "        \n",
    "        if response.xpath(xpath_objetosc).extract() == []: # jeżeli jest tylko jedna objętość to zescrapuj response.url\n",
    "            yield scrapy.Request(response.url, self.parse_product)\n",
    "            \n",
    "        else: # jeśli jest wiele objętości wygeneruj ich listę i scrapuj wszystko\n",
    "            for url in response.xpath(xpath_objetosc).extract():\n",
    "                href = response.urljoin(url)\n",
    "                yield scrapy.Request(href, self.parse_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b61d3917-510e-4247-b366-8fa85ce28705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 01:42:59 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: scrapybot)\n",
      "2023-02-03 01:42:59 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.1, Twisted 22.10.0, Python 3.9.4 (tags/v3.9.4:1f2e308, Apr  6 2021, 13:40:21) [MSC v.1928 64 bit (AMD64)], pyOpenSSL 23.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 39.0.0, Platform Windows-10-10.0.19041-SP0\n",
      "2023-02-03 01:42:59 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 30,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/101.0.4951.34 Safari/537.36'}\n",
      "2023-02-03 01:42:59 [py.warnings] WARNING: c:\\users\\norbert\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scrapy\\utils\\request.py:231: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-02-03 01:42:59 [py.warnings] WARNING: c:\\users\\norbert\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scrapy\\extensions\\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details\n",
      "  exporter = cls(crawler)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.34 Safari/537.36'\n",
    "})\n",
    "\n",
    "process.crawl(ProductsSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b63d50a7-22a6-42b9-bb8c-520d0b4e02d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjl = pd.read_json('output.jl', lines=True, dtype = str) # wczytanie wyników\n",
    "# ponownie cena promocyjna jest traktowana jako reguralna, więc przesuwam wszystko w lewo\n",
    "dfjl[\"cena\"] = np.where(dfjl['cena'] == 'None', dfjl[\"cena promo\"], dfjl[\"cena\"]) \n",
    "dfjl[\"cena promo\"] =np.where(dfjl[\"cena promo\"] == dfjl[\"cena\"], np.nan, dfjl['cena promo'])\n",
    "dfjl = dfjl[dfjl['cena'] != 'None']\n",
    "dfjl=dfjl.dropna(axis=0)\n",
    "dfjl['cena promo'] = dfjl['cena promo'].apply(lambda x: float(x.replace(',','.')) if type(x) == str else x)\n",
    "dfjl['cena'] = dfjl['cena'].apply(lambda x: float(x.replace(',','.')) if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3ae9c5a-4e20-41bf-a2cc-7ec12c82053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapisuje do excela\n",
    "dfjl.to_excel('wynik3.xlsx', sheet_name='Arkusz', index = False, freeze_panes = [1,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
