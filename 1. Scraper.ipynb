{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5dfa853-4345-4e7f-92fa-9acd447b6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import requests\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f634b244-c988-48f1-b098-6dea6ca52fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.rossmann.pl/kategoria/Perfumy,8512?Page=1&PageSize=96' # link do kategorii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f52091f-7745-4e60-851c-94ea9c6f0789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korzystam z BS, aby wydobyć ingformację na temat numeru ostatniej zakładki\n",
    "headers = {'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.34 Safari/537.36'}\n",
    "page = requests.get(url, headers = headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "zakres_max = soup.find('a', href = True, class_ = \"pages__last\").next_element \n",
    "zakres_max = int(zakres_max)\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99672ae-35a9-455c-93e3-6caaed2a6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzę listę startowych adresów\n",
    "urls = []\n",
    "for i in range(1,zakres_max+1):\n",
    "    url = url.replace(f'Page={i-1}',f'Page={i}')\n",
    "    urls.append(url) # generuję listę start_urls do scrapera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1759b6ef-13e4-4df5-9ae7-665ee6c2e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format pliku wynikowego\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('output.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c4d284-ff0b-4bf8-8603-11a7b5cb6519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProductsSpider(scrapy.Spider):\n",
    "    \n",
    "    name = 'products'\n",
    "    start_urls = urls\n",
    "    \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, \n",
    "        'FEED_FORMAT':'json',                                 \n",
    "        'FEED_URI': 'output.json'\n",
    "        ,'DOWNLOAD_DELAY': 3 # opóźnienie w sekundach, czas scrapowania około 10 minut\n",
    "        ,'RANDOMIZE_DOWNLOAD_DELAY' : True # losowość opóźnień: (0.5,1.5)*lag\n",
    "    }\n",
    "    \n",
    "    def parse_product(self, response):\n",
    "        \n",
    "        xpath_name = '//h1[@class=\"h1\"]/text()' # ścieżka do nazwy \n",
    "        xpath_EAN = \"//*[contains(text(), 'Kod EAN')]/following-sibling::text()[1]\" # ścieżka do EAN \n",
    "        xpath_price = '//meta[@property=\"product:price:amount\"]/@content' # ścieżka do ceny\n",
    "        xpath_price_promo = '//meta[@property=\"product:sale_price:amount\"]/@content' # ścieżka do ceny promocyjnej\n",
    "        \n",
    "        name = ''.join(response.xpath(xpath_name).getall())\n",
    "        EAN = response.xpath(xpath_EAN).get()\n",
    "        price = response.xpath(xpath_price).get()\n",
    "        price_promo = response.xpath(xpath_price_promo).get()\n",
    "        \n",
    "        yield {\n",
    "                'Name':name,\n",
    "                'EAN': EAN,\n",
    "                'cena': price,\n",
    "                'cena promo': price_promo,\n",
    "                'url': response.url\n",
    "                }\n",
    "        \n",
    "    def parse(self,response):\n",
    "        \n",
    "        xpath_url = '//a[@class = \"tile-product__name\"]/@href' # ścieżka do poszczególnego produktu na zakładce\n",
    "        \n",
    "        for url in response.xpath(xpath_url).extract(): # wydobądź wszystkie produkty na karcie i pętla po każdym z nich\n",
    "            href = response.urljoin(url)\n",
    "            yield scrapy.Request(href, self.parse_product) # wywołaj funkcję scrapowania pojedynczego produktu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "116ca33a-49ea-4c6e-8d3d-1382bbe9bfaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 01:38:03 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: scrapybot)\n",
      "2023-02-03 01:38:03 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.1, Twisted 22.10.0, Python 3.9.4 (tags/v3.9.4:1f2e308, Apr  6 2021, 13:40:21) [MSC v.1928 64 bit (AMD64)], pyOpenSSL 23.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 39.0.0, Platform Windows-10-10.0.19041-SP0\n",
      "2023-02-03 01:38:03 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 30,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/101.0.4951.34 Safari/537.36'}\n",
      "2023-02-03 01:38:03 [py.warnings] WARNING: c:\\users\\norbert\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scrapy\\utils\\request.py:231: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-02-03 01:38:03 [py.warnings] WARNING: c:\\users\\norbert\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scrapy\\extensions\\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details\n",
      "  exporter = cls(crawler)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.34 Safari/537.36'\n",
    "})\n",
    "\n",
    "process.crawl(ProductsSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c122c0-0237-4f0f-b85d-86ee30254319",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjl = pd.read_json('output.jl', lines=True, dtype = str) # wczytywanie pliku wynikowego z dysku\n",
    "dfjl['EAN'] = dfjl['EAN'].apply(lambda x: x.replace(' ','')) # usuwam spacje z EAN \n",
    "dfjl_ = dfjl[dfjl['cena promo'] != 'None'] # usuwam produkty, które nie są w promocji\n",
    "dfjl_.to_excel('Wynik1.xlsx', sheet_name='Arkusz', index = False, freeze_panes = [1,0]) # zapisanie do excela"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
